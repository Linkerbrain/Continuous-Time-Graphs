{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff6a53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import HeteroData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab4208",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae71ecbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>476496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>486432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>482803200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>474422400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>475372800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394903</th>\n",
       "      <td>15569</td>\n",
       "      <td>57287</td>\n",
       "      <td>496454400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394904</th>\n",
       "      <td>6783</td>\n",
       "      <td>57287</td>\n",
       "      <td>497232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394905</th>\n",
       "      <td>35430</td>\n",
       "      <td>57288</td>\n",
       "      <td>496800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394906</th>\n",
       "      <td>3542</td>\n",
       "      <td>57288</td>\n",
       "      <td>496886400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394907</th>\n",
       "      <td>49597</td>\n",
       "      <td>57288</td>\n",
       "      <td>496627200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394908 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            u      i          t\n",
       "0           0      0  476496000\n",
       "1           1      0  486432000\n",
       "2           2      1  482803200\n",
       "3           3      1  474422400\n",
       "4           4      1  475372800\n",
       "...       ...    ...        ...\n",
       "394903  15569  57287  496454400\n",
       "394904   6783  57287  497232000\n",
       "394905  35430  57288  496800000\n",
       "394906   3542  57288  496886400\n",
       "394907  49597  57288  496627200\n",
       "\n",
       "[394908 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/Beauty.csv').rename({\"user_id\":\"u\", \"item_id\":\"i\", \"time\":\"t\"}, axis=1)\n",
    "df.head()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b29551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-ordering and fixing time sequences...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12887</td>\n",
       "      <td>473731200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49582</td>\n",
       "      <td>475372800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>476496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4732</td>\n",
       "      <td>476496001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5760</td>\n",
       "      <td>476496002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394903</th>\n",
       "      <td>52201</td>\n",
       "      <td>57191</td>\n",
       "      <td>493689601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394904</th>\n",
       "      <td>52202</td>\n",
       "      <td>57190</td>\n",
       "      <td>493603200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394905</th>\n",
       "      <td>52202</td>\n",
       "      <td>57191</td>\n",
       "      <td>493603201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394906</th>\n",
       "      <td>52203</td>\n",
       "      <td>57277</td>\n",
       "      <td>490924800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394907</th>\n",
       "      <td>52203</td>\n",
       "      <td>57255</td>\n",
       "      <td>496886400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394908 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            u      i          t\n",
       "0           0  12887  473731200\n",
       "1           0  49582  475372800\n",
       "2           0      0  476496000\n",
       "3           0   4732  476496001\n",
       "4           0   5760  476496002\n",
       "...       ...    ...        ...\n",
       "394903  52201  57191  493689601\n",
       "394904  52202  57190  493603200\n",
       "394905  52202  57191  493603201\n",
       "394906  52203  57277  490924800\n",
       "394907  52203  57255  496886400\n",
       "\n",
       "[394908 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prep\n",
    "def refine_time(data):\n",
    "    \"\"\"\n",
    "    assures items bought by a user don't have the exact same time\n",
    "    5, 1, 2, 2, 8 -> 1, 2, 3, 5, 8\n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.sort_values(['t'], kind='mergesort')\n",
    "    time_seq = data['t'].values\n",
    "    time_gap = 1\n",
    "    \n",
    "    for i, da in enumerate(time_seq[0:-1]):\n",
    "        if time_seq[i] == time_seq[i+1] or time_seq[i] > time_seq[i+1]:\n",
    "            time_seq[i+1] = time_seq[i+1] + time_gap\n",
    "            time_gap += 1\n",
    "            \n",
    "    data['t'] = time_seq\n",
    "    \n",
    "    return  data\n",
    "\n",
    "def remove_less_than_n_transactions_users(dataf, n):\n",
    "    transactions_per_customer = dataf['u'].value_counts()\n",
    "    \n",
    "    valid_customers = transactions_per_customer[transactions_per_customer>=n].index\n",
    "    \n",
    "    return dataf[dataf['u'].isin(valid_customers)]\n",
    "\n",
    "print(\"Re-ordering and fixing time sequences...\")\n",
    "df = df.groupby('u').apply(refine_time).reset_index(drop=True)\n",
    "df['t'] = df['t'].astype('int64')\n",
    "\n",
    "\n",
    "# This does not work yet since the u's and i's need to be remapped to a continuous range again\n",
    "# min_n = 5\n",
    "# print(f\"Removing users with less than {min_n} transactions\")\n",
    "# df = remove_less_than_n_transactions_users(df, min_n)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dd225f",
   "metadata": {},
   "source": [
    "# Sample algoritme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081f8e8b",
   "metadata": {},
   "source": [
    "We sample efficiently by splitting the process up in 3 steps:\n",
    "\n",
    "## Step 1 - Create 'dictionary'\n",
    "\n",
    "Create dictionary of n recent interactions of each user/item\n",
    "\n",
    "made as a big numpy array `u_connections` and `i_connections` met shape (u+1, n) en (i+1, n).\n",
    "\n",
    "index 0 is om aan te geven dat ie geen connecties meer heeft\n",
    "\n",
    "dus stel je wil de items van user [5, 6, 7, 8] weten dan kan je doen u_connections[6, 7, 8, 9]\n",
    "\n",
    "u_connections = [[     0      0      0 ...      0      0      0]\n",
    " [    32     33     34 ...     39     40     41]\n",
    " [    42     43     44 ...      0      0      0]\n",
    " ...\n",
    " [394902 394903      0 ...      0      0      0]\n",
    " [394904 394905      0 ...      0      0      0]\n",
    " [394906 394907      0 ...      0      0      0]]\n",
    " \n",
    " \n",
    "## Step 2 - get_user_network\n",
    "\n",
    "Tweede stap is om het sample algoritme toe te passen, oftwel steeds de items van de users, dan de users van die items, enzovoort. Bij de vorige step hebben we stiekem ook opgeslagen welke transactie nummers van de aankopen er bij horen, en die slaan we op. Dus nu kunnen we de transacties verzamelen die gesampled zijn als edges. En dan eindigen dus we met een subset van de hele dataset, die beperkt is tot die set users en items.\n",
    "\n",
    "\n",
    "## Step 3 - make_graph_object\n",
    "\n",
    "Met deze functie parsen we tot slot die subset van de dataframe naar het dataformaat dat we willen. Hier wordt set gemaakt van users, items en ook de oui en oiu (hoeveelste item van user het is). TODO: Hier moet ook een opsplitsing worden gemaakt voor elke t, oftwel na elk item dat de target user heeft gekocht. Op dit moment is het alleen voor t=-1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4fc33",
   "metadata": {},
   "source": [
    "Zorgen/mysteries om nog op te lossen\n",
    "\n",
    "- in het paper halen ze users met > x transacties weg, dat is nu nog lastig omdat het voor de lookup table een continuus range moet zijn\n",
    "\n",
    "- users kunnen meer dan n transacties hebben in de gesamplede ding\n",
    "\n",
    "- hoort het per timestep op nieuw gesampled te worden? wij samplen een keer voor einde van dataset en snijden dan het weg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b3c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created user dictionaries\n",
      "Created item dictionaries\n",
      "Created database of 52204 users and 57289 items\n"
     ]
    }
   ],
   "source": [
    "# create dictionaries\n",
    "\n",
    "# n is max number of recent transactions per node sampled\n",
    "n = 10\n",
    "\n",
    "# -- build User most recent transaction lists --\n",
    "u_connection_list = [np.zeros(n)]\n",
    "u_transaction_list = [np.zeros(n)]\n",
    "\n",
    "for u, us_transactions in df.groupby('u'):\n",
    "    bought = us_transactions['i'].values[-n:]\n",
    "    \n",
    "    zero_padded = np.zeros(n)\n",
    "    zero_padded[:len(bought)] = bought + 1 # offset by 1 for dummy\n",
    "    \n",
    "    u_connection_list.append(zero_padded)\n",
    "    \n",
    "    transaction_idx = us_transactions['i'].index.values[-n:]\n",
    "    \n",
    "    zero_padded_t = np.zeros(n)\n",
    "    zero_padded_t[:len(transaction_idx)] = transaction_idx\n",
    "    \n",
    "    u_transaction_list.append(zero_padded_t)\n",
    "\n",
    "print(\"Created user dictionaries\")\n",
    "\n",
    "# -- build Item most recent transaction lists --\n",
    "i_connection_list = [np.zeros(n)]\n",
    "i_transaction_list = [np.zeros(n)]\n",
    "\n",
    "for i, is_transactions in df.groupby('i'):\n",
    "    bought = is_transactions['u'].values[-n:]\n",
    "    \n",
    "    zero_padded = np.zeros(n)\n",
    "    zero_padded[:len(bought)] = bought + 1 # offset by 1 for dummy\n",
    "    \n",
    "    i_connection_list.append(zero_padded)\n",
    "    \n",
    "    transaction_idx = is_transactions['u'].index.values[-n:]\n",
    "    \n",
    "    zero_padded_t = np.zeros(n)\n",
    "    zero_padded_t[:len(transaction_idx)] = transaction_idx\n",
    "    \n",
    "    i_transaction_list.append(zero_padded_t)\n",
    "\n",
    "print(\"Created item dictionaries\")\n",
    "\n",
    "# -- parse to array --\n",
    "\n",
    "u_connections = np.stack(u_connection_list).astype(np.int32)\n",
    "u_transactions = np.stack(u_transaction_list).astype(np.int32)\n",
    "\n",
    "i_connections = np.stack(i_connection_list).astype(np.int32)\n",
    "i_transactions = np.stack(i_transaction_list).astype(np.int32)\n",
    "\n",
    "print(f\"Created database of {len(u_connections)-1} users and {len(i_connections)-1} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85b36006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 52204 users'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_users = df['u'].unique()\n",
    "f\"There are {len(all_users)} users\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e9e4f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user_ids:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([   39,    40,    41, ..., 52093, 52094, 52095])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2077,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'item_ids:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([   17,    43,    84, ..., 57264, 57267, 57277])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7941,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'trans_ids:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([   339,    340,    341, ..., 394238, 394239, 394240])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(14131,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get user network\n",
    "\n",
    "def get_user_network(index, m=2):\n",
    "    # u_m and i_m are the sets of explored nodes\n",
    "    u_m = np.array([0]) # 0 is dummy\n",
    "    i_m = np.array([0])\n",
    "    \n",
    "    # transactions of sampled nodes\n",
    "    transactions_m = np.array([0])\n",
    "    \n",
    "    # u_temp and i_temp are the sets of unexplored nodes\n",
    "    u_temp = np.array([index+1]) # initialize as the given index\n",
    "    i_temp = u_connections[u_temp] # initialize as its purchases\n",
    "    \n",
    "    # add initialized purchases to transaction base\n",
    "    new_transactions = u_transactions[u_temp].flatten()\n",
    "    transactions_m = np.union1d(transactions_m, new_transactions)\n",
    "        \n",
    "    for j in range(m):\n",
    "        new_users = np.unique(i_connections[i_temp])\n",
    "        u_temp = np.union1d(u_temp, new_users)\n",
    "        \n",
    "        new_transactions = i_transactions[i_temp].flatten()\n",
    "        transactions_m = np.union1d(transactions_m, new_transactions)\n",
    "        \n",
    "        u_temp = np.setdiff1d(u_temp, u_m, assume_unique=True)\n",
    "        u_m = np.union1d(u_m, u_temp)\n",
    "        \n",
    "        if len(u_temp)==0:\n",
    "            break\n",
    "            \n",
    "        new_items = np.unique(u_connections[u_temp])\n",
    "        i_temp = np.union1d(i_temp, new_items)\n",
    "        \n",
    "        new_transactions = u_transactions[u_temp].flatten()\n",
    "        transactions_m = np.union1d(transactions_m, new_transactions)\n",
    "        \n",
    "        i_temp = np.setdiff1d(i_temp, i_m, assume_unique=True)\n",
    "        i_m = np.union1d(i_temp, i_m)\n",
    "        \n",
    "        if len(i_temp)==0:\n",
    "            break\n",
    "    \n",
    "    # [1:] to ignore first element since its dummy 0\n",
    "    # -1 to offset back (it was offset to allow for dummy 0)\n",
    "    return u_m[1:]-1, i_m[1:]-1, transactions_m[1:]\n",
    "\n",
    "user_ids, item_ids, transaction_ids = get_user_network(41)\n",
    "\n",
    "display(\"user_ids:\", user_ids, user_ids.shape, \"item_ids:\", item_ids, item_ids.shape, \"trans_ids:\", transaction_ids, transaction_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4da14e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # benchmark run on all users\n",
    "# st = time.time()\n",
    "# selected_nodes = {}\n",
    "# for u in tqdm(all_users[::-1]):\n",
    "#     users, items, trans = get_user_network(u)\n",
    "    \n",
    "#     selected_nodes[u] = trans\n",
    "    \n",
    "# print(f\"{time.time()-st} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e63006be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 make graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "273cfe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_oui(df):\n",
    "    \"\"\"\n",
    "    oui = o_u^i = order of u−i interaction\n",
    "    = the position of item i in all items that the u has interacted with\n",
    "    \n",
    "    i is u's item #oui\n",
    "    \"\"\"\n",
    "    return df.groupby(\"u\")[\"t\"].rank(\"first\")\n",
    "\n",
    "def compute_oiu(df):\n",
    "    \"\"\"\n",
    "    oiu = o_i^u = order of i−u interaction\n",
    "    = the position of user u in all users that the i has interacted with\n",
    "    \n",
    "    u is i's buyer #oiu\n",
    "    \"\"\"\n",
    "    return df.groupby(\"i\")[\"t\"].rank(\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b96c00fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  y=17,\n",
       "  \u001b[1mu\u001b[0m={ x=[2030] },\n",
       "  \u001b[1mi\u001b[0m={ x=[7444] },\n",
       "  \u001b[1m(u, bought, i)\u001b[0m={\n",
       "    edge_index=[2030, 7444],\n",
       "    oui=[13074],\n",
       "    oiu=[13074]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_graph_object(user_index, transaction_ids):\n",
    "    \"\"\"\n",
    "    Makes PyTorch Heterograph not temporal for now\n",
    "    \"\"\"\n",
    "    data = HeteroData()\n",
    "    \n",
    "    sub_df = df.loc[transaction_ids]\n",
    "\n",
    "    # get important transactions\n",
    "    user_sequence_df = sub_df[sub_df['u']==user_index]\n",
    "    final_item = user_sequence_df.iloc[-1]\n",
    "\n",
    "    # remove transactions from the future\n",
    "    sub_df = sub_df[sub_df['t'] < final_item['t']]\n",
    "    \n",
    "    if len(sub_df) < 1:\n",
    "        return data\n",
    "\n",
    "    # make graph\n",
    "    \n",
    "    # remap\n",
    "    mapping_u = {u_id : i for i, u_id in enumerate(sub_df['u'].unique())}\n",
    "    mapping_i = {i_id : i for i, i_id in enumerate(sub_df['i'].unique())}\n",
    "\n",
    "    sub_df['u'] = sub_df['u'].map(mapping_u)\n",
    "    sub_df['i'] = sub_df['i'].map(mapping_i)\n",
    "\n",
    "    # make edge index\n",
    "    users = torch.tensor(sub_df['u'].values)\n",
    "    items = torch.tensor(sub_df['i'].values)\n",
    "\n",
    "    # make edge weights\n",
    "    relative_time = final_item['t'] - sub_df['t'].values\n",
    "    weights = torch.tensor(1 - relative_time / max(relative_time))**3 # SHOULD BE EXPERIMENTED WITH this is unofficial\n",
    "    \n",
    "    # build object\n",
    "    \n",
    "    data['u'].x = torch.tensor(list(mapping_u.keys()))\n",
    "    data['i'].x = torch.tensor(list(mapping_i.keys()))\n",
    "\n",
    "    data['u', 'bought', 'i'].edge_index = torch.sparse_coo_tensor(\n",
    "        torch.stack((users, items)),\n",
    "        weights,\n",
    "        size=(len(mapping_u), len(mapping_i))\n",
    "    ).coalesce()\n",
    "    \n",
    "    data['u', 'bought', 'i'].oui = torch.tensor(compute_oui(sub_df).values) # can maybe be done beforehand TODO\n",
    "    data['u', 'bought', 'i'].oiu = torch.tensor(compute_oiu(sub_df).values)\n",
    "    \n",
    "    data.y = final_item['i']   \n",
    "    \n",
    "    return data\n",
    "\n",
    "user_ids, item_ids, transaction_ids = get_user_network(41)\n",
    "make_graph_object(41, transaction_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e1ad0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f1470d03e640b19a11aeace5137a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3617141246795654 seconds\n"
     ]
    }
   ],
   "source": [
    "# benchmark\n",
    "\n",
    "np.random.shuffle(all_users)\n",
    "min_graph_size = 100\n",
    "\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "graphs = []\n",
    "\n",
    "failed = 0\n",
    "for u in tqdm(all_users[:250]):\n",
    "    user_ids, item_ids, transaction_ids = get_user_network(u)\n",
    "    \n",
    "    if len(transaction_ids) < min_graph_size:\n",
    "        failed += 1\n",
    "        continue\n",
    "        \n",
    "    graph = make_graph_object(u, transaction_ids)\n",
    "    \n",
    "    del(user_ids)\n",
    "    del(item_ids)\n",
    "    del(transaction_ids)\n",
    "    \n",
    "    if len(graph) > 0:\n",
    "        graphs.append(graph)\n",
    "    \n",
    "print(f\"{time.time()-st} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec06fbc1",
   "metadata": {},
   "source": [
    "# DGSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30c0bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4991598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_dense_mul(s, d):\n",
    "    \"\"\"\n",
    "    elementwise multiply sparse and dense matrix of same size\n",
    "    \"\"\"\n",
    "    i = s._indices()\n",
    "    v = s._values()\n",
    "    dv = d[i[0,:], i[1,:]]  # get values from relevant entries of dense matrix\n",
    "    return torch.sparse.FloatTensor(i, v * dv, s.size())\n",
    "\n",
    "def add_messages(messages, adjacency):\n",
    "    \"\"\"\n",
    "    add messages together based on adjacency matrix\n",
    "    \"\"\"\n",
    "    output = torch.zeros((adjacency.shape[0], messages.shape[1]), dtype=float)\n",
    "        \n",
    "    rows, cols = adjacency._indices()\n",
    "    output.index_add_(0, rows, messages[cols] * adjacency._values().unsqueeze(-1))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76b01a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.,  ..., 3., 4., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = graphs[0]\n",
    "oui = graph['u', 'bought', 'i'].oui\n",
    "\n",
    "oui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40788db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 2386 users, 8730 items\n"
     ]
    }
   ],
   "source": [
    "class DGSRConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, graph):\n",
    "        pass\n",
    "        \n",
    "\n",
    "class DGSRNetwork(nn.Module):\n",
    "    def __init__(self,\n",
    "                 user_num, item_num,\n",
    "                 hidden_size,\n",
    "                 user_max, item_max\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \"\"\" init \"\"\"\n",
    "        self.user_vocab_num = user_num\n",
    "        self.item_vocab_num = item_num\n",
    "        \n",
    "        self.user_max = user_max\n",
    "        self.item_max = item_max\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.sqrt_d = np.sqrt(self.hidden_size)\n",
    "        \n",
    "        \"\"\" layers \"\"\"\n",
    "        self.user_embedding = nn.Embedding(self.user_vocab_num, self.hidden_size)\n",
    "        self.item_embedding = nn.Embedding(self.item_vocab_num, self.hidden_size)\n",
    "        \n",
    "        self.w1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False) # Long Term User\n",
    "        self.w2 = nn.Linear(self.hidden_size, self.hidden_size, bias=False) # Long Term Item\n",
    "        \n",
    "        self.w3 = nn.Linear(self.hidden_size, self.hidden_size, bias=False) # Short Term User\n",
    "        self.w4 = nn.Linear(self.hidden_size, self.hidden_size, bias=False) # Short Term Item\n",
    "        \n",
    "        self.wp = nn.Linear(self.hidden_size, self.hidden_size, bias=False) # Recommendations\n",
    "        \n",
    "        self.pV = nn.Embedding(self.user_max, self.hidden_size) # user positional embedding\n",
    "        self.pK = nn.Embedding(self.item_max, self.hidden_size) # item positional embedding\n",
    "        \n",
    "        \n",
    "    def forward(self, graph):\n",
    "        # DEBUG\n",
    "        users_in_graph = graph['u'].x.shape[0]\n",
    "        items_in_graph = graph['i'].x.shape[0]\n",
    "        print(f\"Working with {users_in_graph} users, {items_in_graph} items\")\n",
    "        \n",
    "        # turn node ids into the learned features\n",
    "        u_embedded = self.user_embedding(graph['u'].x) # (u, h)\n",
    "        i_embedded = self.item_embedding(graph['i'].x) # (i, h)\n",
    "        \n",
    "        # --- long term ---\n",
    "        user_messages = self.w1(u_embedded) # (u, h)\n",
    "        item_messages = self.w2(i_embedded) # (i, h)\n",
    "        \n",
    "        # - users to items -\n",
    "                \n",
    "        # message similarity\n",
    "        e = (user_messages) @ (item_messages).T\n",
    "        \n",
    "        oui = graph['u', 'bought', 'i'].oui\n",
    "        rui = 0\n",
    "        # \n",
    "        # calculate attention\n",
    "        # TODO +p\n",
    "        e_ui = (user_messages) @ (item_messages).T / self.sqrt_d # (u, i)\n",
    "        \n",
    "        bought_e_ui = sparse_dense_mul(graph['u', 'bought', 'i'].edge_index, e_ui) # (u, i)\n",
    "        alphas = torch.sparse.softmax(bought_e_ui, 1) # (u, i)\n",
    "        \n",
    "        # TODO +p\n",
    "        longterm_hu = add_messages(item_messages, alphas)\n",
    "        \n",
    "        # - items to users -\n",
    "        \n",
    "        # calculate attention\n",
    "        # TODO +p\n",
    "        e_iu = (item_messages) @ (user_messages).T / self.sqrt_d # (i, u)\n",
    "        \n",
    "        bought_e_iu = sparse_dense_mul(torch.transpose(graph['u', 'bought', 'i'].edge_index, 0, 1), e_iu)\n",
    "        betas = torch.sparse.softmax(bought_e_iu, 1) # (u, i)\n",
    "        \n",
    "        longterm_hi = add_messages(user_messages, betas)\n",
    "        \n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "Make network\n",
    "\"\"\"\n",
    "user_num = len(df['u'].unique())\n",
    "item_num = len(df['i'].unique())\n",
    "\n",
    "hidden_size = 64\n",
    "        \n",
    "network = DGSRNetwork(user_num, item_num, hidden_size, user_max=n, item_max=n)\n",
    "\n",
    "\"\"\"\n",
    "Forward that shit\n",
    "\"\"\"\n",
    "\n",
    "graph = graphs[0]\n",
    "out = network(graph)\n",
    "\n",
    "# Debug\n",
    "# users_in_graph, hidden_size, alphas, item_messages = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abdc6dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "390ddd67",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'item_messages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m add_messages(\u001b[43mitem_messages\u001b[49m, alphas)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'item_messages' is not defined"
     ]
    }
   ],
   "source": [
    "add_messages(item_messages, alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480609c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "longterm_hu = torch.zeros((users_in_graph, hidden_size))  # (u, h)\n",
    "rows, cols = alphas._indices()\n",
    "longterm_hu.index_add_(0, rows, item_messages[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e46f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc154e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_messages[cols].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56848d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas._values().unsqueeze(-1) * item_messages[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c014cbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:clean] *",
   "language": "python",
   "name": "conda-env-clean-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
