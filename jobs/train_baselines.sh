#!/bin/bash

python main.py --dataset beauty train --accelerator gpu --devices 1 --val_epochs 1 --epochs 2 --batch_size 50 --batch_accum 1 --num_loader_workers 3 --partial_save CTGR --train_style dgsr_softmax --val_extra_n_vals 1 --loss_fn ce --convolution SAGE  neighbour --newsampler --n_max_trans 50 --m_order 1 --sample_all
python main.py --dataset beauty train --accelerator cpu --devices 1 --val_epochs 1 --epochs 2 --batch_size 50 --batch_accum 1 --num_loader_workers 3 --partial_save CTGR --train_style dgsr_softmax --val_extra_n_vals 1 --loss_fn ce --homogenous --convolution LG  neighbour --newsampler --n_max_trans 50 --m_order 1 --sample_all
python main.py --dataset beauty train --accelerator cpu --devices 1 --val_epochs 1 --epochs 2 --batch_size 50 --batch_accum 1 --num_loader_workers 3 --partial_save CTGR --train_style dgsr_softmax --val_extra_n_vals 1 --loss_fn ce --homogenous --convolution SG neighbour --newsampler --n_max_trans 50 --m_order 1 --sample_all
python main.py --dataset beauty train --accelerator cpu --devices 1 --val_epochs 1 --epochs 2 --batch_size 50 --batch_accum 1 --num_loader_workers 3 --partial_save CTGR --train_style dgsr_softmax --val_extra_n_vals 1 --loss_fn ce --homogenous --convolution GCN  neighbour --newsampler --n_max_trans 50 --m_order 1 --sample_all
python main.py --dataset beauty train --accelerator cpu --devices 1 --val_epochs 1 --epochs 2 --batch_size 50 --batch_accum 1 --num_loader_workers 3 --partial_save CTGR --train_style dgsr_softmax --val_extra_n_vals 1 --loss_fn ce --split_conv --convolution GCN  neighbour --newsampler --n_max_trans 50 --m_order 1 --sample_all

# Also try: layered_embedding mean,